predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions, title.text="LR ROC Curve")
plot.pr.curve(predictions, title.text="LR Precision/Recall Curve")
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
confusionMatrix(table(factor(lr.predictions.new, u),
factor(test.class.var, u)))
lr.model.best <- lr.model
lr.prediction.values <- predict(lr.model.best, test.feature.vars,
type="response")
predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions, title.text="LR ROC Curve")
plot.pr.curve(predictions, title.text="LR Precision/Recall Curve")
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
library(e1071) # svm model
library(caret) # model training\optimizations
library(kernlab) # svm model for hyperparameters
library(ROCR) # model evaluation
source("performance_plot_utils.R") # plot model metrics
test.feature.vars<- test.data[,-1]
test.class.var<- test.data[,1]
## build initial model with training data
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
svm.model<- svm(formula= formula.init, data = train.data,
kernel="radial", cost=100, gamma=1)
summary(svm.model)
svm.predictions<- predict(svm.model, test.feature.vars)
u= union(svm.predictions,test.class.var)
confusionMatrix(table(factor(svm.predictions, u),
factor(test.class.var, u)))
## svm specific feature selection
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
control <- trainControl(method="repeatedcv", number=10, repeats=2)
model <- train(formula.init, data=train.data, method="svmRadial",
trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance, cex.lab=0.5)
## build new model with selected features
formula.new <- "credit.rating ~ account.balance +
credit.duration.months +savings +
previous.credit.payment.status +credit.amount"
formula.new <- as.formula(formula.new)
svm.model.new <- svm(formula=formula.new, data=train.data,
kernel="radial", cost=10, gamma=0.25)
## predict results with new model on test data and
##evaluate new model performance
svm.predictions.new <- predict(svm.model.new, test.feature.vars)
u= union(svm.predictions.new,test.class.var)
confusionMatrix(table(factor(svm.predictions.new, u),
factor(test.class.var, u)))
cost.weights <- c(0.1,10,100)
gamma.weights <- c(0.01,0.25,0.5,1)
tuning.results <- tune(svm, formula.new,data=train.data,
kernel="radial",
ranges = list(cost=cost.weights,gamma=gamma.weights))
print(tuning.results)
plot(tuning.results, cex.main=0.6, cex.lab=0.8, xaxs="i",yaxs="i")
svm.model.best<- tuning.results$best.model
svm.predictions.best<- predict(svm.model.best,test.feature.vars)
u= union(svm.predictions.best,test.class.var)
confusionMatrix(table(factor(svm.predictions.best, u),
factor(test.class.var, u)))
svm.predictions.best<-predict(svm.model.best,test.feature.vars,
decision.values=T)
svm.prediction.values<- attributes(svm.predictions.best)$decision.values
predictions<- prediction(svm.prediction.values,test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions,title.text = "SVM ROC Curve")
plot.pr.curve(predictions, title.text = "SVM Precision/Recall Curve")
library(e1071) # svm model
library(caret) # model training\optimizations
library(kernlab) # svm model for hyperparameters
library(ROCR) # model evaluation
source("performance_plot_utils.R") # plot model metrics
test.feature.vars<- test.data[,-1]
test.class.var<- test.data[,1]
## build initial model with training data
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
svm.model<- svm(formula= formula.init, data = train.data,
kernel="radial", cost=100, gamma=1)
summary(svm.model)
svm.predictions<- predict(svm.model, test.feature.vars)
u= union(svm.predictions,test.class.var)
confusionMatrix(table(factor(svm.predictions, u),
factor(test.class.var, u)))
## svm specific feature selection
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
control <- trainControl(method="repeatedcv", number=10, repeats=2)
model <- train(formula.init, data=train.data, method="svmRadial",
trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance, cex.lab=0.5)
formula.new <- "credit.rating ~ account.balance +
credit.duration.months +savings +
previous.credit.payment.status +credit.amount"
formula.new <- as.formula(formula.new)
svm.model.new <- svm(formula=formula.new, data=train.data,
kernel="radial", cost=10, gamma=0.25)
## predict results with new model on test data and
##evaluate new model performance
svm.predictions.new <- predict(svm.model.new, test.feature.vars)
u= union(svm.predictions.new,test.class.var)
confusionMatrix(table(factor(svm.predictions.new, u),
factor(test.class.var, u)))
cost.weights <- c(0.1,10,100)
gamma.weights <- c(0.01,0.25,0.5,1)
tuning.results <- tune(svm, formula.new,data=train.data,
kernel="radial",
ranges = list(cost=cost.weights,gamma=gamma.weights))
print(tuning.results)
plot(tuning.results, cex.main=0.6, cex.lab=0.8, xaxs="i",yaxs="i")
svm.model.best<- tuning.results$best.model
svm.predictions.best<- predict(svm.model.best,test.feature.vars)
u= union(svm.predictions.best,test.class.var)
confusionMatrix(table(factor(svm.predictions.best, u),
factor(test.class.var, u)))
svm.predictions.best<-predict(svm.model.best,test.feature.vars,
decision.values=T)
svm.prediction.values<- attributes(svm.predictions.best)$decision.values
predictions<- prediction(svm.prediction.values,test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions,title.text = "SVM ROC Curve")
plot.pr.curve(predictions, title.text = "SVM Precision/Recall Curve")
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
transformed.train <- train.data
transformed.test <- test.data
for (variable in categorical.vars){
new.train.var <- make.names(train.data[[variable]])
transformed.train[[variable]] <- new.train.var
new.test.var <- make.names(test.data[[variable]])
transformed.test[[variable]] <- new.test.var
}
transformed.train <- to.factors(df=transformed.train, variables=categorical.vars)
transformed.test <- to.factors(df=transformed.test, variables=categorical.vars)
transformed.test.feature.vars <- transformed.test[,-1]
transformed.test.class.var <- transformed.test[,1]
grid <- expand.grid(C=c(1,10,100),
sigma=c(0.01, 0.05, 0.1, 0.5, 1))
ctr <- trainControl(method='cv', number=10,
classProbs=TRUE,
summaryFunction=twoClassSummary)
svm.roc.model <- train(formula.init, transformed.train,
method='svmRadial', trControl=ctr,
tuneGrid=grid, metric="ROC")
predictions <- predict(svm.roc.model, transformed.test.feature.vars)
u= union(predictions,transformed.test.class.var)
confusionMatrix(table(factor(predictions, u),
factor(transformed.test.class.var, u)))
svm.predictions<-predict(svm.roc.model,transformed.test.feature.vars,
type="prob")
svm.prediction.values <- svm.predictions[,2]
predictions <- prediction(svm.prediction.values, test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions, title.text="SVM ROC Curve")
plot.pr.curve(predictions, title.text="SVM Precision/Recall Curve")
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
library(e1071) # svm model
library(caret) # model training\optimizations
library(kernlab) # svm model for hyperparameters
library(ROCR) # model evaluation
source("performance_plot_utils.R") # plot model metrics
test.feature.vars<- test.data[,-1]
test.class.var<- test.data[,1]
## build initial model with training data
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
svm.model<- svm(formula= formula.init, data = train.data,
kernel="radial", cost=100, gamma=1)
summary(svm.model)
svm.predictions<- predict(svm.model, test.feature.vars)
u= union(svm.predictions,test.class.var)
confusionMatrix(table(factor(svm.predictions, u),
factor(test.class.var, u)))
## svm specific feature selection
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
control <- trainControl(method="repeatedcv", number=10, repeats=2)
model <- train(formula.init, data=train.data, method="svmRadial",
trControl=control)
importance <- varImp(model, scale=FALSE)
plot(importance, cex.lab=0.5)
## build new model with selected features
formula.new <- "credit.rating ~ account.balance +
credit.duration.months +savings +
previous.credit.payment.status +credit.amount"
formula.new <- as.formula(formula.new)
svm.model.new <- svm(formula=formula.new, data=train.data,
kernel="radial", cost=10, gamma=0.25)
## predict results with new model on test data and
##evaluate new model performance
svm.predictions.new <- predict(svm.model.new, test.feature.vars)
u= union(svm.predictions.new,test.class.var)
confusionMatrix(table(factor(svm.predictions.new, u),
factor(test.class.var, u)))
cost.weights <- c(0.1,10,100)
gamma.weights <- c(0.01,0.25,0.5,1)
tuning.results <- tune(svm, formula.new,data=train.data,
kernel="radial",
ranges = list(cost=cost.weights,gamma=gamma.weights))
print(tuning.results)
plot(tuning.results, cex.main=0.6, cex.lab=0.8, xaxs="i",yaxs="i")
svm.model.best<- tuning.results$best.model
svm.predictions.best<- predict(svm.model.best,test.feature.vars)
u= union(svm.predictions.best,test.class.var)
confusionMatrix(table(factor(svm.predictions.best, u),
factor(test.class.var, u)))
svm.predictions.best<-predict(svm.model.best,test.feature.vars,
decision.values=T)
svm.prediction.values<- attributes(svm.predictions.best)$decision.values
predictions<- prediction(svm.prediction.values,test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions,title.text = "SVM ROC Curve")
plot.pr.curve(predictions, title.text = "SVM Precision/Recall Curve")
auc<- performance(predictions,"auc")
auc<- unlist(slot(auc,"y.values"))
auc<- round(auc,4)
auc
library(rpart)# tree models
library(caret) # feature selection
library(rpart.plot) # plot dtree
library(ROCR) # model evaluation
library(e1071) # tuning model
source("performance_plot_utils.R") # plotting curves
##  Modeling using decision trees
install.packages("rpart.plot")
setwd("E:/R Machine Learning/Section 4")
raw_ratings<- read.csv("product_ratings.csv")
ratings_matrix <- data.matrix(raw_ratings)
rows<- nrow(ratings_matrix)
columns <- ncol(ratings_matrix)
K<-2
X<- matrix(runif(rows*K), nrow=rows, byrow=TRUE)
Y <- matrix(runif(columns*K), nrow=columns, byrow=TRUE)
mf_based_ucf <- function(ratings_matrix, X, Y, K, epoch=5000, alpha=0.0002, beta=0.02){
#transpose Y
Y <- t(Y)
# Iterate epoch number of times
for (step in seq(epoch)){
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
# error
eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])
# gradient calculation
for (k in seq(K)){
X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j] - beta * X[i, k])
Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k] - beta * Y[k, j])
}
}
}
}
# Overall Squared Error Calculation
e = 0
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
e = e + (ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j]))^2
for (k in seq(K)){
e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)
}
}
}
}
# stop if error falls below this threshold
if (e < 0.001){
break
}
}
#inner product
pR <- X %*% Y
pR <- round(pR, 2)
return (pR)
}
epoch <- 10000
View(Y)
raw_ratings<- read.csv("product_ratings.csv")
ratings_matrix <- data.matrix(raw_ratings)
rows<- nrow(ratings_matrix)
columns <- ncol(ratings_matrix)
K<-2
X<- matrix(runif(rows*K), nrow=rows, byrow=TRUE)
Y <- matrix(runif(columns*K), nrow=columns, byrow=TRUE)
mf_based_ucf <- function(ratings_matrix, X, Y, K, epoch=5000, alpha=0.0002, beta=0.02){
#transpose Y
Y <- t(Y)
# Iterate epoch number of times
for (step in seq(epoch)){
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
# error
eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])
# gradient calculation
for (k in seq(K)){
X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j] - beta * X[i, k])
Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k] - beta * Y[k, j])
}
}
}
}
# Overall Squared Error Calculation
e = 0
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
e = e + (ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j]))^2
for (k in seq(K)){
e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)
}
}
}
}
# stop if error falls below this threshold
if (e < 0.001){
break
}
}
#inner product
pR <- X %*% Y
pR <- round(pR, 2)
return (pR)
}
epoch <- 10000
alpha<- 0.0002
alpha<- 0.0002
raw_ratings<- read.csv("product_ratings.csv")
ratings_matrix <- data.matrix(raw_ratings)
rows<- nrow(ratings_matrix)
columns <- ncol(ratings_matrix)
K<-2
X<- matrix(runif(rows*K), nrow=rows, byrow=TRUE)
Y <- matrix(runif(columns*K), nrow=columns, byrow=TRUE)
mf_based_ucf <- function(ratings_matrix, X, Y, K, epoch=5000, alpha=0.0002, beta=0.02){
#transpose Y
Y <- t(Y)
# Iterate epoch number of times
for (step in seq(epoch)){
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
# error
eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])
# gradient calculation
for (k in seq(K)){
X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j] - beta * X[i, k])
Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k] - beta * Y[k, j])
}
}
}
}
# Overall Squared Error Calculation
e = 0
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
e = e + (ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j]))^2
for (k in seq(K)){
e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)
}
}
}
}
# stop if error falls below this threshold
if (e < 0.001){
break
}
}
#inner product
pR <- X %*% Y
pR <- round(pR, 2)
return (pR)
}
epoch <- 10000
alpha<-0.0002
beta<-0.02
pred.matrix<- mf_based_ucf(ratings_matrix, X, Y, K, epoch = epoch)
colnames(pred.matrix)<- c("iPhone.4","iPhone.5s","Moto.X","Moto.G",
"Nexus.6","One.Plus.One")
colnames(pred.matrix)<- c("iPhone.4","iPhone.5s","Moto.X","Moto.G",
"Nexus.6","One.Plus.One")
colnames(pred.matrix)<- c("iPhone.4","iPhone.5s","Moto.X","Moto.G",
"Nexus.6","One.Plus.One")
colnames(pred.matrix)<-c("iPhone.4","iPhone.5s","Nexus.5",
"Moto.X","Moto.G","Nexus.6","One.Plus.One")
raw_ratings<- read.csv("product_ratings.csv")
ratings_matrix <- data.matrix(raw_ratings)
rows<- nrow(ratings_matrix)
columns <- ncol(ratings_matrix)
K<-2
X<- matrix(runif(rows*K), nrow=rows, byrow=TRUE)
Y <- matrix(runif(columns*K), nrow=columns, byrow=TRUE)
mf_based_ucf <- function(ratings_matrix, X, Y, K, epoch=5000, alpha=0.0002, beta=0.02){
#transpose Y
Y <- t(Y)
# Iterate epoch number of times
for (step in seq(epoch)){
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
# error
eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])
# gradient calculation
for (k in seq(K)){
X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j] - beta * X[i, k])
Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k] - beta * Y[k, j])
}
}
}
}
# Overall Squared Error Calculation
e = 0
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
e = e + (ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j]))^2
for (k in seq(K)){
e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)
}
}
}
}
# stop if error falls below this threshold
if (e < 0.001){
break
}
}
#inner product
pR <- X %*% Y
pR <- round(pR, 2)
return (pR)
}
epoch <- 10000
alpha<-0.0002
beta<-0.02
pred.matrix<- mf_based_ucf(ratings_matrix, X, Y, K, epoch = epoch)
colnames(pred.matrix)<- c("iPhone.4","iPhone.5s","Nexus.5","Moto.X",
"Moto.G","Nexus.6"."One.Plus.One")
raw_ratings<- read.csv("product_ratings.csv")
ratings_matrix <- data.matrix(raw_ratings)
rows<- nrow(ratings_matrix)
columns <- ncol(ratings_matrix)
K<-2
X<- matrix(runif(rows*K), nrow=rows, byrow=TRUE)
Y <- matrix(runif(columns*K), nrow=columns, byrow=TRUE)
mf_based_ucf <- function(ratings_matrix, X, Y, K, epoch=5000, alpha=0.0002, beta=0.02){
#transpose Y
Y <- t(Y)
# Iterate epoch number of times
for (step in seq(epoch)){
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
# error
eij = ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j])
# gradient calculation
for (k in seq(K)){
X[i, k] = X[i, k] + alpha * (2 * eij * Y[k, j] - beta * X[i, k])
Y[k, j] = Y[k, j] + alpha * (2 * eij * X[i, k] - beta * Y[k, j])
}
}
}
}
# Overall Squared Error Calculation
e = 0
for (i in seq(nrow(ratings_matrix))){
for (j in seq(length(ratings_matrix[i, ]))){
if (ratings_matrix[i, j] > 0){
e = e + (ratings_matrix[i, j] - as.numeric(X[i, ] %*% Y[, j]))^2
for (k in seq(K)){
e = e + (beta/2) * (X[i, k]^2 + Y[k, j]^2)
}
}
}
}
# stop if error falls below this threshold
if (e < 0.001){
break
}
}
#inner product
pR <- X %*% Y
pR <- round(pR, 2)
return (pR)
}
epoch <- 10000
alpha<-0.0002
beta<-0.02
pred.matrix<- mf_based_ucf(ratings_matrix, X, Y, K, epoch = epoch)
colnames(pred.matrix)<- c("iPhone.4","iPhone.5s","Nexus.5","Moto.X",
"Moto.G","Nexus.6","One.Plus.One")
pred.matrix
